SIRIUS Project All Hands Meeting

Oak Ridge National Laboratory

Monday, October 19, 2015

Agenda
  9:00 -   9:30             Introduction, Scott Klasky
  9:30 -   9:50        Hasan Abbasi
  9:50 - 10:10              Mark Ainsworth
10:10 - 10:30               Matt Curry
10:30 - 10:50               Break
10:50 - 11:10               Gary Liu
11:10 - 11:30               Jay Lofstead
11:30 - 11:50               Carlos Maltzahn
12:00 -   1:00              Lunch
  1:00 -   1:20             Manish Parashar
  1:20 -   1:40             Feiyi Wang
  1:40 -   2:00             Discussions
  2:00 -   2:30             Break
  2:30 -   3:15        Barney Maccabe

  3:15 -   5:00        Demos and Discussions

--------------------
Scott
Exascale computing initiatie
$90M/yr to software.
Paul Messina (ANL) is overall lead

1 call per month for project (all hands)
biweekly call for executive team

provide opportunity to reduce data in the storage system if the calculation either did not or could not use a method like AMR to reduce data volumes. For cases where data is already reduced, we will just optimize placement to keep important data close.

--------------
Hasan
investigate data utility and how to incorporate utility functions to annotate and decompose data
How does data utility change over time and how do we incorporate this into the features?
BlinkDB.org

-----------------
Mark
By doing some curve fitting, you can store every nth item and then the errors on each other element and yield a much higher losses compression rate. Compression Interpolation Auditor.
instead of 15-20% lossless compression, can achieve 70%+ with a large data set to offer enough overhead to hide the extra data annotations.
-----------------
Matthew
- Sirocco overview
- Focus on storage layer + user layer on top to provide semantics

-----------------
Gary
What is the right IO interface?
How do we do guarantees?
How to annotate data?
add data description to XML listing relationships among vars (with what that relationship means, e.g., “access together”) and the utility (value?) of data.
Specify policies while reading including deadlines and errors

SOSP’11  “differentiated storage services”, SOSP’13 IOflow
 paper
User policy, no support
Complex storage stack
Data descriptions:
how do we describe/annotate data generated from applications?

Preliminary QoS work - through OS virtualization

Soft deadline or hard deadline? Carolos doesn’t like the soft
 part

---------------------
Jay - Metadata challenges for SIRIUS

The challenges:
“Storage device come and go”
“performance variance”
Enhance placement decision based on predicted future use

-------------
Carlos
Casual metadata Rodrigo Fonseca at Brown (HPTS 2015 presentation); also SOSP 2015 and NSDI 2015
90 percentile meet  90% deadline, interesting
BlinkDB - multi-resolution data placement based on workload profiles.

-------------
Manish
- maximize relative data utility to the application and system while reducing access cost
- leverage knowledge about the data and its use within the application to drive data placement and management
- prepare object for reading and take advantage of that knowledge to enhance writing, when possible.
- DataSpaces paper from HPDC 10. Indexing + DHT for data finding
- Service Level Objective vs. Constraint
— goals that will hopefully be met vs. requirements
- look at placement in staging/in compute area storage/SCM to enhance usage
- adaptive application-aware data management

-------------------
Feiyi
- Usability and Manageability
- looking at the performance from the device level
- consider all kinds of operations (read, write, metadata)
- 75% of files are 512 KiB or smaller (~250 M files, 15 PB, half of Atlas
- “disks are like snowflakes"
- pay attention to the whole hardware and software path from compute to storage to get end-to-end performance
- write/read ratio on Atlas file system is 60/40.

----------------------
Barney visit
Notes from Afternoon Session (Barney McCabe present)
----------------------------------------------------

SK gave an overview of the objectives of the project to BM. He mentioned that
next generation machines will have different layers in the storage hierarchy
that will require more sophisticated representations of data. 

SK also talked about the need to 

- quantify expected performance of the storage systems so that the user can
  make informed decisions on what quantities can be reasonably computed. 

- introduce accuracy and error control as a consideration in the analysis
  particularly given that much of the scientific data is specified to a much
  higher precision than the accuracy of the actual data  

- identify appropriate demos that can be used to illustrate and focus the
  research effort. One demo will be the Particle-in-Cell code (PiC) such as the
  one of CS Chang. He stressed the importance of producing demos that can be
  presented to the programme manager early next year e.g. May 2016 as a target. 

BM felt that it was important to get demos working, but that it was also
important to be clear about what we are aiming to demonstrate and to produce
publications.  

CM gave an overview to BM of what he had presented earlier in the day. He
emphasised the importance of providing guaranteed estimates on the quality of
service to enable the user to make informed decisions on possible courses of
action. He also mentioned the possibility of creating a hierarchy of
resolutions for the data that provide alternative approaches for generating
user-defined quantities. 

BM pointed out the difficulty of providing accurate estimates in environments
where the resources are dynamically changing. 

SK mentioned that we would be getting feedback from Feiying on existing state
of the art hardware. 

BM thanked everyone for coming to ORNL and underlined the importance of the
project for ORNL. 

- 
