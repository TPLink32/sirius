\subsubsection{Policies}

One of the key differentiating features this project offers is driving storage
decisions through policies rather than continuing the current model of allowing
all application to compete, without restriction, for part or all of the storage
resources. This current approach leads to intereference
effects~\cite{lofstead:2010:adaptive} that can greatly impact IO performance
predictability. Further, with the introduction of additional tiers in the
storage stack, the performance variability will increase with greater
competiion for limited high performance resources. Unfettered, this competition
will yield lower performnce for all users than if users either restrict IO
resource uses to a disjoint subset each or even using lower raw performance
resources.

Our policies are driven from multiple different approaches. First, supporting
capability runs is a priority for capability machines. We propose to address
capability run performance by incorporating monitoring for prepartory runs at
smaller scale to profile the application output characteristics both from a
writing velocity and volume, but also for example read patterns for the data
analytics required to generate scientific insights from the raw data. By
discovering approximate data proportions that will likely be the key subsets
targeted by the simulation run, we can generate a policy to preserve a certain
storage portion for high fidelity data storagae and use slower or perhaps lower
fidelity or compressed data storage for less interesting data portions. We will
support spreading data appropriately across the storage hierarchy. In
particular, we will investigate how to place data across different layers to
meet the performance requirements for output while maintaining system
availability for other applications and offering the best possible performance
for the data analytics that will ultimately process this data.

Second, once data has been placed for future performance requirements, policies
must be able to address maintaining data on a priority basis in that location
to deliver on the placement optimization generated by the capability run
profilier.

Third, most future NVM devices have limited write endurance prompting
management to ensure fair use by all machine users. Technologies like
NAND-flash and Phase Change Memory have limited write endurance. By
incorporating policies about the proportion of write endurance a compute
allocation is entitled to, data placement decisions can be made to ensure fair
resource usage. While the offending application will suffer worse IO
performance, other applications that more carefully address their data
intensity on these limited devices will achieve higher overall performnce. Only
by instituting such policies can we encourage application users to adopt
technology to manage the limited resources.

We propose to investigate both offering a policy mechanism and how to implement
these kinds of policies in a way that addresses offering the shortest
end-to-end time for scientific insights.
