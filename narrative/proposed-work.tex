\section{Proposed Research and Methods}
\label{subsec:challenges}

Our research into the storage system and middle ware layers must address
many of these challenges including
\begin{enumerate}
\item How do we describe the user intentions at the API layer and have this
  communicated down to the middle-ware and storage layers?
\item How do we allow users to define their user defined compression
  techniques and have this data read back from the storage system layers?
  Where do we execute the decompression techniques 
\item How do we evaluate the tradeoffs at runtime to guide data placement,
  including the movement of data across the network, across the different
  storage tiers? (data movement and quality tradeoff)
\item Can we use different forms of learning techniques as daemons on the
  system to perform data migration from one storage tier to another? For
  example, if we see that a user is looking at one time slice after another
  for a certain object in their dataset which is in the slower tiers of the
  hierarchy, do we automatically propane up the data which has not been
  requested in the hope that this will be requested data? (prediction and
  prefetching, user defined compression on movement)
\item Can we understand the true need of campaign storage and understand the
  possible impact of the campaign storage if we run a hadoop-like
  file-system instead of a lustre/gpfs file system? (additional layers)
\item Can we limit the amount of data duplication? Data space is going to be
  very constrained on the exascale system so we must ensure that minimal
  copies are made of data, and when data is duplicated, they are removed
  through a garbage collection routine. (space management)
\item Can we build a model to give us the time estimates during the reading
  and writing phases, so that rules can be in place from the user
  perspective to make adaptive decisions. For example, if the file system
  says that reading will take 3 months, users can they place in rules to
  then read in a subset of data, and they can understand which data can be
  read quickly and which pieces will take more time. (estimation)
\item Can we understand how to place code in the system which will allow
  data-regeneration to take place. (regeneration)
\item How does the storage system do a better job in managing request from
  all of the users on a LCF than today? We realize that today users who have
  a better middlware system can often lock other users from getting high
  performance when they are running. If we have the concept of currency
  which is eventually used in the same extent as node-hours, then users will
  have to be able to think about how much storage and how much bandwidth
  they can choose. One question that needs to be understood is if there are
  times when the system sees that there are very few storage system
  resources being used, then the lucky users can get the bandwidth cheaper
  than at times of heavy usage. How can we enforce this? (Fairness)
\item How do we manage all of the metdata not only from the principle
  objects, but from the sub-objects? How well will this scale when we have
  users who can potentially create billions of objects from their
  simulation? (scalability and discovery)


\item Add plug-in architecture to Sirocco to support selective data compression
\item Add specific tier destinations command to Sirocco (assuming that the caching mechansism cannot achieve the desired effects).
\item Develop profiling system to determine how a data set is used during preparation runs prior to a capability run to determine how to optimize data placement for capability run analytics.

\end{enumerate}

{\bf \color{red}we need to condense these challenges into a few basic principles - 4 at most - SAK}

We propose to overcome these challenges by pioneering a new {\bf knowledge-centric approach} to a dynamic storage system
and I/O layer which takes into account user prioritization and utility to optimize the SSIO layer. The approach is based on 
four underlying principles:
  
\underline{Principle 1: A knowledge-centric system} , let user knowledge  to define data policies. talk about this pieces...

\underline{Principle 2: A SSIO system which integrates system knowledge together with application knowledge} to understand
how to organize data in the deep storage hierarchy

\underline{Principle 3: Predictable Performance in the SSIO layer} so that intelligent choices can be made by both the user and the system

\input{narrative/data-description} % includes data-desc, apis, and qos-app.   

%\subsection{Application Interface}

%\input{narrative/data-desc}
\input{narrative/data-reduction} % includes data-reorg and the api specs move to the above section -
\input{narrative/data-reorg}
%\input{narrative/qos-app}
\input{narrative/placement}
%\input{narrative/policies}
%\input{narrative/apis}

%\subsection{Storage System}

\input{narrative/migration}
\input{narrative/resource-mgmt}
\input{narrative/qos-storage}
%\input{narrative/discovery}
\input{narrative/eviction-metrics}
\input{narrative/naming-service}
%\input{narrative/time-estimation}
\input{narrative/infrastructure}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../proposal"
%%% End:
