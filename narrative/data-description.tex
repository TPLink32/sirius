\subsection{Description of Data}
In order for the middleware and storage layer to understand data,
I/O intentions, and act accordingly, describing data in a way that can
be understood by the system is needed. In this project, this is achieved 
by managing data as \textit{objects}.
An object is the smallest unit of data that consists of raw data and metadata,
and a user space variable, such as \textit{temperature}, may consist of a collection
of objects possibly with different accuracy or resolution.
A key advantage of representing data as \textit{objects}, rather than 
bytes, is that it allows data semantics, user intentions, QoS requirements, and
the relationship between user data to be readily captured and embedded with the 
raw data. As an example, retrieving a 3D field data generated from a simulation 
and then visualizing it requires the coordinates and connectivity variable 
1) to be accessed together and 2) with low latency in order to achieve a good user experience. 
The description of data, as enabled by managing data as objects, bridges 
the semantics gap between applications, middleware, and storage systems,
and allows the system to understand user-level data, execute QoS requirements and policies, and
optimize application and system performance.

%The new APIs will enable the bridge by specifying selectable performance/quality/- cost tradeoffs 
%from both the application and system perspectives based upon the user guided rules/policy and 
%runtime system monitoring status. It allows the middleware to make best possible decisions from 
%the feedback of storage system knowledge, such that it will embed user intentions and the available 
%system storage. 
%We want the system to give the users a certain amount of currency 
%in terms of bandwidth, storage space on each level, and latency expectations. These notions will be fuzzy 
%but they will allow the user to make ad-hoc decisions to figure out what needs to be saved.

The description of data is essentially metadata and it may include conventional attributes, such as 
data type, size, dimensionality, relationship to other data, and etc. In particular,
relationship to other data objects can be captured by implementing \textit{soft links}
and different types of relationships can be expressed by different types of soft links. 
In this project, a key metadata attribute
that enables QoS scheduling, data placement, and ???, is \textit{data utility value}, which
captures the priority of objects - it is to our belief that
for exascale science, users must prioritize a small set of objects to be saved on 
higher-level capacity-limited storage layer
to avoid the slow access to large-capacity lower-level storage, such as tapes.
We propose a new technique, described by a utility function plugged in by a user, 
where objects can be cast into multiple buckets of data, and each bucket can be prioritized 
differently according to its utility value.
Once this is done, the middleware system will construct the description of data, re-organize
and place data to achieve the desired QoS goals and policies.

In the meanwhile, the user would like the ability to get a certain amount of Quality of Service 
such that they can then make decisions when the expected bandwidth, 
for example is less than what they desire and will then place in a certain set 
of rules which the system can make autonomic decisions to help decide what should be done.
A key insight in this proposed project has been the increased interaction of
the application with the storage system. Towards this end, we propose to
address the quality of service requirements by providing the application
with mechanisms to specify the quality of I/O service, interrogate the
storage system, and react to the responses. Guided by our past work in
ADIOS \cite{lofstead2008flexible} we propose to explore the design of two
mechanisms for this purpose. 

Firstly, we will explore the augmentation of
I/O application programing interfaces (I/O APIs) to allow applications to
both specify timing and quality information and also query the storage
system for timing estimates. If user decide to write or read data to or from hierarchical storage systems, 
they will rely on the API to send their intentions for inquiry and examine the system status, 
including how much data they would like to write/read, desired bandwidth, data compression method, etc, 
or the user can express their intension of writing data right now no matter what the traffic is now.
Through this interface we expect the
application and user to gain insights into how long a single output or input
call will take given the required quality information, and then react to
these estimates by adjusting the quality or restricting the scope of the
data required. Likewise we will explore how an application can provide
timing information to the storage system to allow the storage system to make
optimization decisions to best meet the requirements from the application. 

Secondly, we will also explore external data annotations, such as those
provided by the configuration file in ADIOS. Through the use of these
external augmentation the user can provide insights to the storage system on
the relative value of the data, expected life time and performance
characteristics, as well as relationships between different data sets. With
this information the storage system can make optimizations specific to a use
case. We expect these augmentations to be particularly important for
eviction of data from a storage layer, and migration of data sets to a
different storage layer. 

The capability of APIs provide dynamic runtime information to user and make the system 
more transparent to them rather than a black box. The end user could analyze or visualize data 
in a more comfortable position, where they are able to envision 
how much longer they are going to wait for data. 

\paragraph{State of the art:} ADIOS implements a binary-packed data format that allows
data characteristics such as min, max and index to be wrapped around data chunks. A
direct benefit is that each data chunk can be operated independently and I/O concurrently
can be maximized. We will build upon this capability and further augment the format
to express data utility. Recently DAMSEL \cite{damsel} provides a rich metadata representation
and management layer that captures the relationship between data blocks for scientific applications.
This allows application data to be mapped to storage system efficiently, without overburdening
users to managing complex data model, such as AMR, from the user space. However, the aspect of 
data importance hasn't been explored, which we believe will be important for exascale storage solutions. 

\paragraph{Proposed research approach:} 
We will design and develop new APIs through which users can describe the utility of data
based on their expectations. This can be done by plugging user level functions that will
partition user level data into objects and be executed by the middleware to calculate the 
utility value for each object. The utility value along with other metadata will be encapsulated
by the middleware and utilized by the underlying storage system to management data placement.

We will design an updated I/O API that will expand on the current POSIX I/O
semantics by adding new information to the I/O request. We will explore the
set of application level hints that can be easily provided to the storage
system in order for the storage system to make the most appropriate
optimization decisions. In particular, we expect the application to provide
hints on the length of time before the output data is persistent and
visible to users, and the expected lifetime of the data for data output
calls. For read calls we expect the set of hints to combine latency and
precision requirements. Additional hints will also be investigated. 

We will also develop a new type of querying system that allows application
to ask the storage system about completion timing information, the response
being an estimate provided by the storage system. We will explore how these
query functions can be integrated into common applications with minimal code
disruptions, and the set of policies that applications can use to respond to
this new information. We will also explore how applications can query the
storage system to gain insights on available space in different tiers and
how applications can tailor their output data to match the available space. 
Finally we will study the use of an external data annotation system that can
provide information to the storage system without requiring the application
to be recompiled. 

\paragraph{Challenges:}
The design of new APIs posses both technical and adoption challenges. Here
we will only consider the technical challenges. The proposed set of APIs aim
to expose broad system level environmental information to the application,
and allow the application to adapt dynamically based on this information.
One aspect of this challenge is the design of an interrogative API that
enables a back-and-forth between the application and the storage system to
enable the application to receive enough information to make adaptation
decisions. 


